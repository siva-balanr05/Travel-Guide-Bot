# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b9U7M8sZE1VSa00zkj9Z5DK-mVjlIreD
"""

import os
import torch
import gradio as gr
from PIL import Image
import pytesseract
import fitz  # PyMuPDF for PDFs
import docx
import pandas as pd

from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    AutoModelForVision2Seq,
    AutoProcessor,
    pipeline,
)

pip install gradio transformers accelerate torch

!pip install pillow pytesseract pymupdf python-docx pandas

TXT_MODEL = "HuggingFaceTB/SmolLM3-3B"
IMG_MODEL = "Qwen/Qwen2-VL-2B-Instruct"

print("Loading text model:", TXT_MODEL)
txt_tokenizer = AutoTokenizer.from_pretrained(TXT_MODEL, trust_remote_code=True)
txt_model = AutoModelForCausalLM.from_pretrained(
    TXT_MODEL,
    device_map="auto",
    torch_dtype="auto",
    trust_remote_code=True
)
txt_generator = pipeline(
    "text-generation",
    model=txt_model,
    tokenizer=txt_tokenizer,
    trust_remote_code=True
)

print("Loading vision-language model:", IMG_MODEL)
img_tokenizer = AutoTokenizer.from_pretrained(IMG_MODEL, trust_remote_code=True)
img_processor = AutoProcessor.from_pretrained(IMG_MODEL, trust_remote_code=True)
img_model = AutoModelForVision2Seq.from_pretrained(
    IMG_MODEL,
    device_map="auto",
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    trust_remote_code=True
).eval()



def build_prompt(user_message, extra_context=""):
    system = (
        "You are TravelBuddy ‚Äî a friendly travel assistant. "
        "Your job is to answer questions about travel. "
        "If the user provides a file or image, you must carefully analyze its details "
        "and then answer based on BOTH the question and the uploaded content. "
        "If the uploaded content has a place, date, or booking info, use it in your reply."
    )
    prompt_parts = [system, "\n---\nConversation:\n"]
    if extra_context:
        prompt_parts.append(f"User: {user_message}\nüìé Uploaded content:\n{extra_context}\nAssistant:")
    else:
        prompt_parts.append(f"User: {user_message}\nAssistant:")
    return "\n".join(prompt_parts)

def extract_text_from_file(file_path: str) -> str:
    text = ""
    ext = os.path.splitext(file_path)[-1].lower()
    try:
        if ext == ".txt":
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                text = f.read()
        elif ext == ".pdf":
            doc = fitz.open(file_path)
            for page in doc:
                text += page.get_text()
        elif ext == ".docx":
            doc = docx.Document(file_path)
            for para in doc.paragraphs:
                text += para.text + "\n"
        elif ext == ".csv":
            df = pd.read_csv(file_path)
            text = df.to_string()
        else:
            text = f"Unsupported file format: {ext}"
    except Exception as e:
        text = f"(Error reading file: {e})"
    return text.strip()

def ocr_text_from_image(image_path: str) -> str:
    try:
        img = Image.open(image_path)
        text = pytesseract.image_to_string(img)
        return text.strip()
    except Exception as e:
        return f"(OCR error: {e})"

def qwen_vl_answer(image_path: str, user_message: str) -> str:
    global img_processor, img_model
    try:
        travel_prompt = (
            "You are TravelBuddy ‚Äî a friendly travel assistant.\n"
            "You are given a user question and an uploaded travel image.\n"
            "First, analyze the image for any details (landmarks, tickets, prices, locations, etc). "
            "Then, directly answer the user's question using BOTH the image and the question. "
            "If the question is about cost, time, or recommendations, use clues from the image (such as tickets, signs, or context) to give a specific answer. "
            "If the image does not contain enough information, say so, but always try to connect your answer to the user's question.\n\n"
            f"User question: {user_message}"
        )
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": travel_prompt},
                    {"type": "image", "image": image_path},
                ],
            }
        ]
        prompt_text = img_processor.apply_chat_template(
            messages,
            add_generation_prompt=True
        )
        pil_image = Image.open(image_path).convert("RGB")
        inputs = img_processor(
            text=[prompt_text],
            images=[pil_image],
            return_tensors="pt"
        ).to(img_model.device)
        with torch.inference_mode():
            generated_ids = img_model.generate(
                **inputs,
                max_new_tokens=400
            )
        output = img_processor.batch_decode(
            generated_ids,
            skip_special_tokens=True
        )[0]
        return output.strip()
    except Exception as e:
        return f"(VLM error: {e})"

def chat_fn(message, history, file=None, image=None):
    # history is not used for context, but required by ChatInterface
    greetings = ["hi", "hello", "hey", "thanks", "thank you"]
    if not message or message.strip() == "":
        return "Please enter a question."
    if image is not None:
        return qwen_vl_answer(image, message)
    extra_context = ""
    if file is not None:
        extra_context += extract_text_from_file(file.name)
    prompt = build_prompt(message, extra_context)
    try:
        response = txt_generator(
            prompt,
            max_new_tokens=250,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
        )
        if "generated_text" in response[0]:
            text = response[0]["generated_text"].split("Assistant:")[-1].strip()
        else:
            text = response[0]["text"].split("Assistant:")[-1].strip()
    except Exception as e:
        text = f"(Error during generation: {e})"
    return text

gr.ChatInterface(
    fn=chat_fn,
    title="üåç TravelBuddy ‚Äî Your Travel Chat Assistant",
    description=(
        "Ask me anything about travel! "
        "You can also upload a travel-related file (txt, pdf, docx, csv) or an image (ticket, landmark, etc). "
        "I'll answer your question using the uploaded content if provided."
    ),
    additional_inputs=[
        gr.File(label="Upload Travel File", file_types=[".txt", ".pdf", ".docx", ".csv"]),
        gr.Image(type="filepath", label="Upload Travel Image")
    ],
    theme=gr.themes.Soft(),
    examples=[
        ["How much does it cost to visit the Eiffel Tower?"],
        ["Suggest a 3-day itinerary for Rome."],
        ["What is the best time to visit Japan?"],
    ]
).queue().launch(share=True)



